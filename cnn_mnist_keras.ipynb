{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist_keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4Oy+NcyNPJkIJ7O9TgUlw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishankarve/NeuralNetworks/blob/main/cnn_mnist_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hcuyCQTD5Ipi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "w-XLMq0Q5yzS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlQilVIX6BEb",
        "outputId": "54764b22-40a3-420a-f748-277cd7fce068"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample only 20k images for training\n",
        "idx = np.random.randint(x_train.shape[0], size = 20000)\n",
        "x_train = x_train[idx, :]\n",
        "y_train = y_train[idx]\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0-xGE7Z6Mdg",
        "outputId": "76021766-4d56-43da-8c53-4b907b6fa49b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 28, 28)\n",
            "(20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify input dimensions of each image\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# batch size, number of classes, epochs\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12"
      ],
      "metadata": {
        "id": "9bM4Dafv6ZVS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape x_train and x_test\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYffJA6L64YS",
        "outputId": "67f8f95f-a0cb-49d1-fb55-b2b9897883f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class labels (from digits) to one-hot encoded vectors\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQZ_durK6_Sx",
        "outputId": "11e32f65-cc4a-48ba-b85b-61bd65e982a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# originally, the pixels are stored as ints\n",
        "x_train.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3JdtOe_7CiL",
        "outputId": "728bfc03-4cc3-461d-e2bb-21309a2f076b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert int to float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalise\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "zYhRwCrF7Ejg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = Sequential()\n",
        "\n",
        "# a keras convolutional layer is called Conv2D\n",
        "# help(Conv2D)\n",
        "# note that the first layer needs to be told the input shape explicitly\n",
        "\n",
        "# first conv layer\n",
        "'''\n",
        "Layer-1 (Conv2D): We have used 32 kernels of size (3, 3), \n",
        "and each kernel has a single bias, so we have \n",
        "32 x 3 x 3 (weights) + 32 (biases) = 320 parameters (all trainable). \n",
        "Note that the kernels have only one channel since \n",
        "the input images are 2D (grayscale). By default, \n",
        "a convolutional layer uses stride of 1 and no padding, \n",
        "so the output from this layer is of shape 26 x 26 x 32, \n",
        "as shown in the summary above (the first element None \n",
        "is for the batch size).\n",
        "'''\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape)) # input shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# second conv layer\n",
        "'''\n",
        "Layer-2 (Conv2D): We have used 64 kernels of size (3, 3), \n",
        "but this time, each kernel has to convolve a tensor of \n",
        "size (26, 26, 32) from the previous layer. Thus, \n",
        "the kernels will also have 32 channels, and \n",
        "so the shape of each kernel is (3, 3, 32) \n",
        "(and we have 64 of them). So we have \n",
        "64 x 3 x 3 x 32 (weights) + 64 (biases) = 18496 parameters (all trainable). \n",
        "The output shape is (24, 24, 64) since each kernel \n",
        "produces a (24, 24) feature map.\n",
        "'''\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), \n",
        "                 activation='relu'))\n",
        "'''\n",
        "Max pooling: The pooling layer gets the (24, 24, 64) \n",
        "input from the previous conv layer and produces a \n",
        "(12, 12, 64) output (the default pooling uses stride of 2). \n",
        "There are no trainable parameters in the pooling layer.\n",
        "'''\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "'''\n",
        "The Dropout layer does not alter the output shape \n",
        "and has no trainable parameters.\n",
        "'''\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# flatten and put a fully connected layer\n",
        "'''\n",
        "The Flatten layer simply takes in the (12, 12, 64) \n",
        "output from the previous layer and 'flattens' it \n",
        "into a vector of length 12 x 12 x 64 = 9216.\n",
        "'''\n",
        "model.add(Flatten())\n",
        "'''\n",
        "The Dense layer is a plain fully connected layer \n",
        "with 128 neurons. It takes the 9216-dimensional \n",
        "output vector from the previous layer (layer l-1) as \n",
        "the input and has 128 x 9216 (weights) + 128 (biases) = 1179776 \n",
        "trainable parameters. The output of this layer is a 128-dimensional vector.'''\n",
        "model.add(Dense(128, activation='relu')) # fully connected\n",
        "'''\n",
        "The Dropout layer simply drops a few neurons.\n",
        "'''\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# softmax layer\n",
        "'''\n",
        "Finally, we have a Dense softmax layer with \n",
        "10 neurons which takes the 128-dimensional \n",
        "vector from the previous layer as input. \n",
        "It has 128 x 10 (weights) + 10 (biases) = 1290 trainable parameters.\n",
        "'''\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUr7M2NE7GUZ",
        "outputId": "f44e1237-de5b-4f20-f795-5385c857bc57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usual cross entropy loss\n",
        "# choose any optimiser such as adam, rmsprop etc\n",
        "# metric is accuracy\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4RUjwHAD8xCv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "# this should take around 10-15 minutes when run locally on a windows/mac PC \n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7l-vMqu83Cr",
        "outputId": "fbafbbda-89b1-4492-dc26-5d16be0348e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "157/157 [==============================] - 54s 338ms/step - loss: 2.2957 - accuracy: 0.1191 - val_loss: 2.2756 - val_accuracy: 0.1708\n",
            "Epoch 2/12\n",
            "148/157 [===========================>..] - ETA: 2s - loss: 2.2730 - accuracy: 0.1571"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model on test data\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "4-zc9Bif85Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.metrics_names)"
      ],
      "metadata": {
        "id": "Bnn0v2QI9D6r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}